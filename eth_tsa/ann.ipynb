{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>eth_open</th>\n",
       "      <th>eth_high</th>\n",
       "      <th>eth_low</th>\n",
       "      <th>eth_close</th>\n",
       "      <th>eth_volumefrom</th>\n",
       "      <th>eth_volumeto</th>\n",
       "      <th>btc</th>\n",
       "      <th>xrp</th>\n",
       "      <th>eos</th>\n",
       "      <th>ltc</th>\n",
       "      <th>xlm</th>\n",
       "      <th>xmr</th>\n",
       "      <th>vixcls</th>\n",
       "      <th>twexb</th>\n",
       "      <th>effr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-07-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.25</td>\n",
       "      <td>103.1938</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-07-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.25</td>\n",
       "      <td>103.1938</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.25</td>\n",
       "      <td>103.1938</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-07-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.97</td>\n",
       "      <td>103.1938</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-07-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.93</td>\n",
       "      <td>103.1938</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  eth_open  eth_high  eth_low  eth_close  eth_volumefrom  \\\n",
       "0 2010-07-16       0.0       0.0      0.0        0.0             0.0   \n",
       "1 2010-07-17       0.0       0.0      0.0        0.0             0.0   \n",
       "2 2010-07-18       0.0       0.0      0.0        0.0             0.0   \n",
       "3 2010-07-19       0.0       0.0      0.0        0.0             0.0   \n",
       "4 2010-07-20       0.0       0.0      0.0        0.0             0.0   \n",
       "\n",
       "   eth_volumeto      btc  xrp  eos  ltc  xlm  xmr  vixcls     twexb  effr  \n",
       "0           0.0  0.04951  0.0  0.0  0.0  0.0  0.0   26.25  103.1938  0.19  \n",
       "1           0.0  0.08584  0.0  0.0  0.0  0.0  0.0   26.25  103.1938  0.19  \n",
       "2           0.0  0.08080  0.0  0.0  0.0  0.0  0.0   26.25  103.1938  0.19  \n",
       "3           0.0  0.07474  0.0  0.0  0.0  0.0  0.0   25.97  103.1938  0.19  \n",
       "4           0.0  0.07921  0.0  0.0  0.0  0.0  0.0   23.93  103.1938  0.18  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"../datasets/df.json\", orient=\"split\")\n",
    "#data = data.apply(lambda x: x if x > 0 else 0)\n",
    "data = data.fillna(0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.shift(1).eth_close\n",
    "y = y[1:]\n",
    "x = data.iloc[1:,7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['btc', 'xrp', 'eos', 'ltc', 'xlm', 'xmr', 'vixcls', 'twexb', 'effr'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2980,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2975 samples, validate on 5 samples\n",
      "Epoch 1/100\n",
      "2975/2975 [==============================] - 1s 271us/step - loss: 92511.6649 - r2: -2.0168 - val_loss: 11886.8066 - val_r2: -308.9738\n",
      "Epoch 2/100\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 26117.1330 - r2: 0.3168 - val_loss: 423.9050 - val_r2: -10.0542\n",
      "Epoch 3/100\n",
      "2975/2975 [==============================] - 0s 33us/step - loss: 15031.2240 - r2: 0.6259 - val_loss: 939.0871 - val_r2: -23.4887\n",
      "Epoch 4/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 12759.2125 - r2: 0.6742 - val_loss: 1792.4492 - val_r2: -45.7419\n",
      "Epoch 5/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 12523.1278 - r2: 0.6810 - val_loss: 5308.1460 - val_r2: -137.4212\n",
      "Epoch 6/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 10298.8355 - r2: 0.7064 - val_loss: 3899.7781 - val_r2: -100.6950\n",
      "Epoch 7/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 10875.3700 - r2: 0.6860 - val_loss: 2633.5234 - val_r2: -67.6747\n",
      "Epoch 8/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 9967.4433 - r2: 0.7478 - val_loss: 1840.3861 - val_r2: -46.9920\n",
      "Epoch 9/100\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 11178.6218 - r2: 0.7242 - val_loss: 1600.9417 - val_r2: -40.7480\n",
      "Epoch 10/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 9927.3660 - r2: 0.7381 - val_loss: 1694.5551 - val_r2: -43.1891\n",
      "Epoch 11/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 9211.4544 - r2: 0.7798 - val_loss: 2693.9539 - val_r2: -69.2506\n",
      "Epoch 12/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 8882.8116 - r2: 0.7752 - val_loss: 5519.7280 - val_r2: -142.9387\n",
      "Epoch 13/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 8563.7604 - r2: 0.7314 - val_loss: 4900.6289 - val_r2: -126.7943\n",
      "Epoch 14/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 7400.2607 - r2: 0.7952 - val_loss: 2601.1890 - val_r2: -66.8315\n",
      "Epoch 15/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 8663.5777 - r2: 0.7822 - val_loss: 7253.8462 - val_r2: -188.1595\n",
      "Epoch 16/100\n",
      "2975/2975 [==============================] - 0s 33us/step - loss: 7054.8949 - r2: 0.8242 - val_loss: 6358.7109 - val_r2: -164.8169\n",
      "Epoch 17/100\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 8219.1934 - r2: 0.7809 - val_loss: 3919.1235 - val_r2: -101.1995\n",
      "Epoch 18/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 7602.3556 - r2: 0.7413 - val_loss: 10543.2812 - val_r2: -273.9385\n",
      "Epoch 19/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 9113.5487 - r2: 0.7816 - val_loss: 2787.0576 - val_r2: -71.6785\n",
      "Epoch 20/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 7387.4612 - r2: 0.8052 - val_loss: 6313.3579 - val_r2: -163.6342\n",
      "Epoch 21/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 7497.8070 - r2: 0.8082 - val_loss: 8738.4092 - val_r2: -226.8726\n",
      "Epoch 22/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 8288.8422 - r2: 0.8005 - val_loss: 2764.0679 - val_r2: -71.0790\n",
      "Epoch 23/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 6930.3957 - r2: 0.7947 - val_loss: 10449.2549 - val_r2: -271.4865\n",
      "Epoch 24/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 8034.7689 - r2: 0.7952 - val_loss: 7625.7319 - val_r2: -197.8572\n",
      "Epoch 25/100\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 8664.7678 - r2: 0.7817 - val_loss: 12577.4033 - val_r2: -326.9825\n",
      "Epoch 26/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 9291.9612 - r2: 0.7506 - val_loss: 2601.3989 - val_r2: -66.8370\n",
      "Epoch 27/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 7544.9716 - r2: 0.8146 - val_loss: 4981.7593 - val_r2: -128.9100\n",
      "Epoch 28/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 7055.0461 - r2: 0.8216 - val_loss: 5573.3984 - val_r2: -144.3382\n",
      "Epoch 29/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 7434.6970 - r2: 0.8185 - val_loss: 2870.5547 - val_r2: -73.8558\n",
      "Epoch 30/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 8343.3328 - r2: 0.7918 - val_loss: 4163.6577 - val_r2: -107.5762\n",
      "Epoch 31/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 7204.8832 - r2: 0.8038 - val_loss: 2472.2402 - val_r2: -63.4689\n",
      "Epoch 32/100\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 6956.5429 - r2: 0.8156 - val_loss: 3567.6577 - val_r2: -92.0343\n",
      "Epoch 33/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 7675.8157 - r2: 0.8256 - val_loss: 10602.9668 - val_r2: -275.4949\n",
      "Epoch 34/100\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 6761.5829 - r2: 0.8128 - val_loss: 12420.7236 - val_r2: -322.8968\n",
      "Epoch 35/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 7226.5145 - r2: 0.8107 - val_loss: 10820.4316 - val_r2: -281.1658\n",
      "Epoch 36/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 6946.0676 - r2: 0.8246 - val_loss: 7100.0688 - val_r2: -184.1494\n",
      "Epoch 37/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 7811.6678 - r2: 0.8252 - val_loss: 6127.4482 - val_r2: -158.7863\n",
      "Epoch 38/100\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 6693.0779 - r2: 0.8295 - val_loss: 7014.0459 - val_r2: -181.9062\n",
      "Epoch 39/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 6767.8612 - r2: 0.7921 - val_loss: 3134.9382 - val_r2: -80.7502\n",
      "Epoch 40/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 7086.0847 - r2: 0.8187 - val_loss: 6172.5986 - val_r2: -159.9636\n",
      "Epoch 41/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 7953.2578 - r2: 0.8061 - val_loss: 3115.7134 - val_r2: -80.2489\n",
      "Epoch 42/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 7383.0696 - r2: 0.8003 - val_loss: 1735.3215 - val_r2: -44.2522\n",
      "Epoch 43/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 7052.0615 - r2: 0.8168 - val_loss: 2536.1406 - val_r2: -65.1353\n",
      "Epoch 44/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 6726.3383 - r2: 0.8127 - val_loss: 4081.7703 - val_r2: -105.4408\n",
      "Epoch 45/100\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 6830.5689 - r2: 0.8251 - val_loss: 5085.4814 - val_r2: -131.6148\n",
      "Epoch 46/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 6830.5947 - r2: 0.8366 - val_loss: 4844.8672 - val_r2: -125.3402\n",
      "Epoch 47/100\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 7319.9672 - r2: 0.8042 - val_loss: 3290.7019 - val_r2: -84.8121\n",
      "Epoch 48/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 6278.4186 - r2: 0.8431 - val_loss: 4795.4536 - val_r2: -124.0517\n",
      "Epoch 49/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 6990.6387 - r2: 0.8136 - val_loss: 5948.3008 - val_r2: -154.1146\n",
      "Epoch 50/100\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 7022.4248 - r2: 0.8310 - val_loss: 4245.7803 - val_r2: -109.7178\n",
      "Epoch 51/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 7550.1256 - r2: 0.8228 - val_loss: 3196.6909 - val_r2: -82.3605\n",
      "Epoch 52/100\n",
      "2975/2975 [==============================] - 0s 55us/step - loss: 6168.0151 - r2: 0.8429 - val_loss: 2206.7886 - val_r2: -56.5467\n",
      "Epoch 53/100\n",
      "2975/2975 [==============================] - 0s 56us/step - loss: 7216.4984 - r2: 0.8138 - val_loss: 2313.9290 - val_r2: -59.3406\n",
      "Epoch 54/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 6563.8499 - r2: 0.8410 - val_loss: 4249.8062 - val_r2: -109.8227\n",
      "Epoch 55/100\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 6789.7107 - r2: 0.8218 - val_loss: 3402.9302 - val_r2: -87.7386\n",
      "Epoch 56/100\n",
      "2975/2975 [==============================] - 0s 34us/step - loss: 6368.8376 - r2: 0.8397 - val_loss: 1340.0676 - val_r2: -33.9451\n",
      "Epoch 57/100\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 7674.6422 - r2: 0.8090 - val_loss: 2361.0569 - val_r2: -60.5696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 6210.8863 - r2: 0.8304 - val_loss: 604.2487 - val_r2: -14.7571\n",
      "Epoch 59/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 6839.2944 - r2: 0.8286 - val_loss: 3140.1997 - val_r2: -80.8874\n",
      "Epoch 60/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 6214.4966 - r2: 0.8408 - val_loss: 398.2691 - val_r2: -9.3857\n",
      "Epoch 61/100\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 6101.7956 - r2: 0.8256 - val_loss: 743.4827 - val_r2: -18.3879\n",
      "Epoch 62/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 6389.8887 - r2: 0.8265 - val_loss: 1930.1641 - val_r2: -49.3331\n",
      "Epoch 63/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 5782.9992 - r2: 0.8573 - val_loss: 1342.6764 - val_r2: -34.0131\n",
      "Epoch 64/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 6105.8985 - r2: 0.8465 - val_loss: 2452.3618 - val_r2: -62.9506\n",
      "Epoch 65/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 6142.8109 - r2: 0.8404 - val_loss: 697.9115 - val_r2: -17.1995\n",
      "Epoch 66/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 5537.5356 - r2: 0.8603 - val_loss: 446.7427 - val_r2: -10.6498\n",
      "Epoch 67/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 5980.2889 - r2: 0.8320 - val_loss: 1558.1421 - val_r2: -39.6319\n",
      "Epoch 68/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 5794.3805 - r2: 0.8347 - val_loss: 2130.1863 - val_r2: -54.5491\n",
      "Epoch 69/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 6693.6117 - r2: 0.8328 - val_loss: 2816.6687 - val_r2: -72.4506\n",
      "Epoch 70/100\n",
      "2975/2975 [==============================] - 0s 35us/step - loss: 6339.3992 - r2: 0.8241 - val_loss: 513.6165 - val_r2: -12.3936\n",
      "Epoch 71/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 6308.4831 - r2: 0.8500 - val_loss: 1022.7835 - val_r2: -25.6713\n",
      "Epoch 72/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 6563.1078 - r2: 0.8439 - val_loss: 285.9236 - val_r2: -6.4561\n",
      "Epoch 73/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 5628.0516 - r2: 0.8479 - val_loss: 1936.6500 - val_r2: -49.5023\n",
      "Epoch 74/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 5911.0408 - r2: 0.7527 - val_loss: 417.0544 - val_r2: -9.8756\n",
      "Epoch 75/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 6523.0111 - r2: 0.8435 - val_loss: 89.2574 - val_r2: -1.3276\n",
      "Epoch 76/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 5407.1576 - r2: 0.8574 - val_loss: 250.1797 - val_r2: -5.5240\n",
      "Epoch 77/100\n",
      "2975/2975 [==============================] - 0s 54us/step - loss: 5912.9732 - r2: 0.8305 - val_loss: 106.5775 - val_r2: -1.7792\n",
      "Epoch 78/100\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 5949.8749 - r2: 0.8600 - val_loss: 419.5820 - val_r2: -9.9415\n",
      "Epoch 79/100\n",
      "2975/2975 [==============================] - 0s 49us/step - loss: 5680.5724 - r2: 0.8506 - val_loss: 87.3006 - val_r2: -1.2765\n",
      "Epoch 80/100\n",
      "2975/2975 [==============================] - 0s 51us/step - loss: 5068.0239 - r2: 0.8542 - val_loss: 506.9304 - val_r2: -12.2193\n",
      "Epoch 81/100\n",
      "2975/2975 [==============================] - 0s 46us/step - loss: 5038.5713 - r2: 0.8734 - val_loss: 407.3587 - val_r2: -9.6227\n",
      "Epoch 82/100\n",
      "2975/2975 [==============================] - 0s 50us/step - loss: 5314.1124 - r2: 0.8558 - val_loss: 167.8361 - val_r2: -3.3767\n",
      "Epoch 83/100\n",
      "2975/2975 [==============================] - 0s 44us/step - loss: 6255.4229 - r2: 0.8288 - val_loss: 77.7925 - val_r2: -1.0286\n",
      "Epoch 84/100\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 5561.0386 - r2: 0.8684 - val_loss: 515.0544 - val_r2: -12.4311\n",
      "Epoch 85/100\n",
      "2975/2975 [==============================] - 0s 47us/step - loss: 5509.1461 - r2: 0.8667 - val_loss: 184.0352 - val_r2: -3.7991\n",
      "Epoch 86/100\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 5600.4542 - r2: 0.8614 - val_loss: 382.9854 - val_r2: -8.9872\n",
      "Epoch 87/100\n",
      "2975/2975 [==============================] - 0s 41us/step - loss: 5625.7682 - r2: 0.8569 - val_loss: 68.6939 - val_r2: -0.7913\n",
      "Epoch 88/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 5175.6960 - r2: 0.8568 - val_loss: 119.5765 - val_r2: -2.1182\n",
      "Epoch 89/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 5298.6259 - r2: 0.8652 - val_loss: 472.4684 - val_r2: -11.3206\n",
      "Epoch 90/100\n",
      "2975/2975 [==============================] - 0s 40us/step - loss: 5914.5896 - r2: 0.8270 - val_loss: 134.5112 - val_r2: -2.5077\n",
      "Epoch 91/100\n",
      "2975/2975 [==============================] - 0s 42us/step - loss: 5795.4949 - r2: 0.5157 - val_loss: 750.6727 - val_r2: -18.5754\n",
      "Epoch 92/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 4701.7675 - r2: 0.8758 - val_loss: 77.7502 - val_r2: -1.0275\n",
      "Epoch 93/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 5427.3806 - r2: 0.8669 - val_loss: 66.7458 - val_r2: -0.7405\n",
      "Epoch 94/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 5058.7037 - r2: 0.8822 - val_loss: 70.9990 - val_r2: -0.8515\n",
      "Epoch 95/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 5347.8509 - r2: 0.8669 - val_loss: 1399.5343 - val_r2: -35.4958\n",
      "Epoch 96/100\n",
      "2975/2975 [==============================] - 0s 36us/step - loss: 5451.5602 - r2: 0.8493 - val_loss: 200.3891 - val_r2: -4.2256\n",
      "Epoch 97/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 5922.8089 - r2: 0.8663 - val_loss: 92.8887 - val_r2: -1.4223\n",
      "Epoch 98/100\n",
      "2975/2975 [==============================] - 0s 38us/step - loss: 5273.6147 - r2: 0.8610 - val_loss: 651.1361 - val_r2: -15.9798\n",
      "Epoch 99/100\n",
      "2975/2975 [==============================] - 0s 37us/step - loss: 4423.6637 - r2: 0.8789 - val_loss: 68.0207 - val_r2: -0.7738\n",
      "Epoch 100/100\n",
      "2975/2975 [==============================] - 0s 39us/step - loss: 5940.7151 - r2: 0.8547 - val_loss: 69.1466 - val_r2: -0.8031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb27b06ef0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation = 'relu', input_dim=9))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(4, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true -y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true -K.mean(y_true))) \n",
    "    return ( 1 -SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=[r2])\n",
    "\n",
    "model.fit(np.array(x.iloc[:-5,:]), np.array(y[:-5]), epochs=100, validation_data=(np.array(x.iloc[-5:,:]), np.array(y[-5:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                320       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 1,025\n",
      "Trainable params: 1,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
