{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from datetime import datetime as dt\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "colors = sns.color_palette('deep', 8)\n",
    "sns.set_palette(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>eth_open</th>\n",
       "      <th>eth_high</th>\n",
       "      <th>eth_low</th>\n",
       "      <th>eth_close</th>\n",
       "      <th>eth_volumefrom</th>\n",
       "      <th>eth_volumeto</th>\n",
       "      <th>btc</th>\n",
       "      <th>xrp</th>\n",
       "      <th>eos</th>\n",
       "      <th>ltc</th>\n",
       "      <th>xlm</th>\n",
       "      <th>xmr</th>\n",
       "      <th>vixcls</th>\n",
       "      <th>twexb</th>\n",
       "      <th>effr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-07-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.04951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.25</td>\n",
       "      <td>103.1938</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-07-17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.25</td>\n",
       "      <td>103.1938</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.08080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.25</td>\n",
       "      <td>103.1938</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  eth_open  eth_high  eth_low  eth_close  eth_volumefrom  \\\n",
       "0 2010-07-16       NaN       NaN      NaN        NaN             NaN   \n",
       "1 2010-07-17       NaN       NaN      NaN        NaN             NaN   \n",
       "2 2010-07-18       NaN       NaN      NaN        NaN             NaN   \n",
       "\n",
       "   eth_volumeto      btc  xrp  eos  ltc  xlm  xmr  vixcls     twexb  effr  \n",
       "0           NaN  0.04951  NaN  NaN  NaN  NaN  NaN   26.25  103.1938  0.19  \n",
       "1           NaN  0.08584  NaN  NaN  NaN  NaN  NaN   26.25  103.1938  0.19  \n",
       "2           NaN  0.08080  NaN  NaN  NaN  NaN  NaN   26.25  103.1938  0.19  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orig = pd.read_json('../datasets/df.json', orient='split')\n",
    "#print(df_orig.info())\n",
    "df_orig.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>eth_open</th>\n",
       "      <th>eth_high</th>\n",
       "      <th>eth_low</th>\n",
       "      <th>eth_close</th>\n",
       "      <th>eth_volumefrom</th>\n",
       "      <th>eth_volumeto</th>\n",
       "      <th>btc</th>\n",
       "      <th>xrp</th>\n",
       "      <th>eos</th>\n",
       "      <th>ltc</th>\n",
       "      <th>xlm</th>\n",
       "      <th>xmr</th>\n",
       "      <th>vixcls</th>\n",
       "      <th>twexb</th>\n",
       "      <th>effr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-07-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.25</td>\n",
       "      <td>103.1938</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-07-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.25</td>\n",
       "      <td>103.1938</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-07-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.08080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.25</td>\n",
       "      <td>103.1938</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  eth_open  eth_high  eth_low  eth_close  eth_volumefrom  \\\n",
       "0 2010-07-16       0.0       0.0      0.0        0.0             0.0   \n",
       "1 2010-07-17       0.0       0.0      0.0        0.0             0.0   \n",
       "2 2010-07-18       0.0       0.0      0.0        0.0             0.0   \n",
       "\n",
       "   eth_volumeto      btc  xrp  eos  ltc  xlm  xmr  vixcls     twexb  effr  \n",
       "0           0.0  0.04951  0.0  0.0  0.0  0.0  0.0   26.25  103.1938  0.19  \n",
       "1           0.0  0.08584  0.0  0.0  0.0  0.0  0.0   26.25  103.1938  0.19  \n",
       "2           0.0  0.08080  0.0  0.0  0.0  0.0  0.0   26.25  103.1938  0.19  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set df for time series\n",
    "df = df_orig.copy()\n",
    "\n",
    "# start at beginning of ethereum\n",
    "#df = df[df.eth_close.isnull().sum():]\n",
    "#df.set_index('date', inplace=True)\n",
    "df.fillna(0, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[1:, 8:]\n",
    "#X.drop(['eth_volumefrom', 'eth_volumeto'], axis=1, inplace=True)\n",
    "#X = df.loc[:, ~df.columns.isin(['eth_close', 'date'])][1:]\n",
    "y = df.shift(1).eth_close[1:]\n",
    "\n",
    "X_train = np.array(X.iloc[:-8,:])\n",
    "X_test = np.array(X.iloc[-8:,:])\n",
    "y_train = np.array(y.iloc[:-8])\n",
    "y_test = np.array(y.iloc[-8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(y_true, y_pred):\n",
    "    SS_res = K.sum(K.square(y_true - y_pred))\n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    rmse = K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2972 samples, validate on 8 samples\n",
      "Epoch 1/100\n",
      "2972/2972 [==============================] - 1s 202us/step - loss: 38617.8485 - r2: 0.0551 - rmse: 81.5315 - val_loss: 9702.2959 - val_r2: -32.4153 - val_rmse: 97.2438\n",
      "Epoch 2/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 15699.6166 - r2: 0.6153 - rmse: 63.3106 - val_loss: 2404.2358 - val_r2: -7.2803 - val_rmse: 46.9257\n",
      "Epoch 3/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 11265.2643 - r2: 0.2605 - rmse: 43.6031 - val_loss: 1560.6307 - val_r2: -4.3749 - val_rmse: 36.8330\n",
      "Epoch 4/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 10112.4254 - r2: 0.7398 - rmse: 39.5347 - val_loss: 1348.0728 - val_r2: -3.6428 - val_rmse: 33.7815\n",
      "Epoch 5/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 8343.1274 - r2: 0.7787 - rmse: 35.1992 - val_loss: 2247.2188 - val_r2: -6.7396 - val_rmse: 45.1665\n",
      "Epoch 6/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 8737.4364 - r2: 0.7717 - rmse: 35.5279 - val_loss: 3648.0972 - val_r2: -11.5643 - val_rmse: 58.6301\n",
      "Epoch 7/100\n",
      "2972/2972 [==============================] - 0s 46us/step - loss: 6701.0767 - r2: 0.8213 - rmse: 31.8910 - val_loss: 956.1252 - val_r2: -2.2930 - val_rmse: 27.2107\n",
      "Epoch 8/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 6767.7519 - r2: 0.8340 - rmse: 31.4477 - val_loss: 2713.7749 - val_r2: -8.3464 - val_rmse: 49.9919\n",
      "Epoch 9/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 6673.2279 - r2: 0.8375 - rmse: 30.2499 - val_loss: 439.6003 - val_r2: -0.5140 - val_rmse: 17.0689\n",
      "Epoch 10/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 6499.7516 - r2: 0.8152 - rmse: 30.1240 - val_loss: 1501.6195 - val_r2: -4.1717 - val_rmse: 35.8489\n",
      "Epoch 11/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 5977.9114 - r2: 0.8458 - rmse: 29.1953 - val_loss: 1853.4468 - val_r2: -5.3834 - val_rmse: 40.4556\n",
      "Epoch 12/100\n",
      "2972/2972 [==============================] - 0s 49us/step - loss: 5947.4066 - r2: 0.8552 - rmse: 28.9803 - val_loss: 2150.3750 - val_r2: -6.4060 - val_rmse: 43.9628\n",
      "Epoch 13/100\n",
      "2972/2972 [==============================] - 0s 61us/step - loss: 6131.6725 - r2: 0.8088 - rmse: 29.1758 - val_loss: 822.3760 - val_r2: -1.8323 - val_rmse: 24.5369\n",
      "Epoch 14/100\n",
      "2972/2972 [==============================] - 0s 44us/step - loss: 5661.5577 - r2: 0.8480 - rmse: 27.3675 - val_loss: 480.0388 - val_r2: -0.6533 - val_rmse: 17.7088\n",
      "Epoch 15/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 6260.4747 - r2: 0.7644 - rmse: 28.8452 - val_loss: 539.8684 - val_r2: -0.8593 - val_rmse: 18.7421\n",
      "Epoch 16/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 6176.9635 - r2: 0.8476 - rmse: 28.6238 - val_loss: 240.0896 - val_r2: 0.1731 - val_rmse: 12.2436\n",
      "Epoch 17/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 6798.9219 - r2: 0.8369 - rmse: 29.2503 - val_loss: 250.6839 - val_r2: 0.1366 - val_rmse: 13.9280\n",
      "Epoch 18/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 5394.2160 - r2: 0.7803 - rmse: 27.2216 - val_loss: 303.6169 - val_r2: -0.0457 - val_rmse: 14.7687\n",
      "Epoch 19/100\n",
      "2972/2972 [==============================] - 0s 44us/step - loss: 5714.9359 - r2: 0.3813 - rmse: 27.5501 - val_loss: 291.7239 - val_r2: -0.0047 - val_rmse: 14.6061\n",
      "Epoch 20/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 5278.9582 - r2: 0.8676 - rmse: 26.9941 - val_loss: 249.5810 - val_r2: 0.1404 - val_rmse: 13.9083\n",
      "Epoch 21/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 5007.9342 - r2: 0.8652 - rmse: 25.8223 - val_loss: 235.8768 - val_r2: 0.1876 - val_rmse: 12.1022\n",
      "Epoch 22/100\n",
      "2972/2972 [==============================] - 0s 40us/step - loss: 4479.7560 - r2: 0.8454 - rmse: 24.8273 - val_loss: 448.0356 - val_r2: -0.5431 - val_rmse: 17.5289\n",
      "Epoch 23/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 4915.0467 - r2: 0.4972 - rmse: 25.2374 - val_loss: 342.1954 - val_r2: -0.1785 - val_rmse: 15.1789\n",
      "Epoch 24/100\n",
      "2972/2972 [==============================] - 0s 40us/step - loss: 4101.1710 - r2: 0.8896 - rmse: 23.9955 - val_loss: 383.6523 - val_r2: -0.3213 - val_rmse: 16.0806\n",
      "Epoch 25/100\n",
      "2972/2972 [==============================] - 0s 39us/step - loss: 4656.8565 - r2: 0.8641 - rmse: 25.1916 - val_loss: 1226.1025 - val_r2: -3.2228 - val_rmse: 31.4913\n",
      "Epoch 26/100\n",
      "2972/2972 [==============================] - 0s 38us/step - loss: 5053.3474 - r2: 0.8597 - rmse: 25.7517 - val_loss: 234.5554 - val_r2: 0.1922 - val_rmse: 12.9560\n",
      "Epoch 27/100\n",
      "2972/2972 [==============================] - 0s 40us/step - loss: 4737.9906 - r2: 0.8466 - rmse: 24.4474 - val_loss: 315.2190 - val_r2: -0.0856 - val_rmse: 14.4925\n",
      "Epoch 28/100\n",
      "2972/2972 [==============================] - 0s 38us/step - loss: 4978.5311 - r2: 0.8666 - rmse: 26.2535 - val_loss: 453.4028 - val_r2: -0.5615 - val_rmse: 17.7080\n",
      "Epoch 29/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 4468.5002 - r2: 0.8843 - rmse: 23.9779 - val_loss: 766.1082 - val_r2: -1.6385 - val_rmse: 23.7530\n",
      "Epoch 30/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 3898.9768 - r2: 0.9009 - rmse: 23.6393 - val_loss: 361.4632 - val_r2: -0.2449 - val_rmse: 15.6509\n",
      "Epoch 31/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 5043.0270 - r2: 0.8734 - rmse: 24.8894 - val_loss: 295.4352 - val_r2: -0.0175 - val_rmse: 13.9219\n",
      "Epoch 32/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 4449.3166 - r2: 0.8918 - rmse: 24.5995 - val_loss: 267.3528 - val_r2: 0.0792 - val_rmse: 12.8362\n",
      "Epoch 33/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 4732.3382 - r2: 0.8910 - rmse: 23.6886 - val_loss: 327.0625 - val_r2: -0.1264 - val_rmse: 14.8364\n",
      "Epoch 34/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 4574.8298 - r2: 0.8823 - rmse: 24.6133 - val_loss: 594.6320 - val_r2: -1.0480 - val_rmse: 20.6867\n",
      "Epoch 35/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 4530.2384 - r2: 0.8850 - rmse: 24.1492 - val_loss: 412.4355 - val_r2: -0.4205 - val_rmse: 16.7677\n",
      "Epoch 36/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 4168.7494 - r2: 0.8960 - rmse: 23.3950 - val_loss: 1064.9742 - val_r2: -2.6678 - val_rmse: 28.7156\n",
      "Epoch 37/100\n",
      "2972/2972 [==============================] - 0s 40us/step - loss: 4227.5450 - r2: 0.8722 - rmse: 23.0336 - val_loss: 537.6187 - val_r2: -0.8516 - val_rmse: 19.4951\n",
      "Epoch 38/100\n",
      "2972/2972 [==============================] - 0s 40us/step - loss: 4014.5029 - r2: 0.9033 - rmse: 22.6567 - val_loss: 1041.8755 - val_r2: -2.5883 - val_rmse: 28.2832\n",
      "Epoch 39/100\n",
      "2972/2972 [==============================] - 0s 39us/step - loss: 4603.0730 - r2: 0.8915 - rmse: 24.0368 - val_loss: 1321.8325 - val_r2: -3.5525 - val_rmse: 32.8571\n",
      "Epoch 40/100\n",
      "2972/2972 [==============================] - 0s 39us/step - loss: 4278.5426 - r2: 0.8919 - rmse: 23.2492 - val_loss: 309.3064 - val_r2: -0.0653 - val_rmse: 14.3599\n",
      "Epoch 41/100\n",
      "2972/2972 [==============================] - 0s 38us/step - loss: 4179.5369 - r2: 0.8756 - rmse: 23.2927 - val_loss: 820.1150 - val_r2: -1.8245 - val_rmse: 24.5723\n",
      "Epoch 42/100\n",
      "2972/2972 [==============================] - 0s 39us/step - loss: 4014.2009 - r2: 0.8460 - rmse: 23.1144 - val_loss: 497.2113 - val_r2: -0.7124 - val_rmse: 18.6126\n",
      "Epoch 43/100\n",
      "2972/2972 [==============================] - 0s 40us/step - loss: 3898.6034 - r2: 0.8976 - rmse: 22.9075 - val_loss: 256.1069 - val_r2: 0.1180 - val_rmse: 12.5179\n",
      "Epoch 44/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 4019.9776 - r2: 0.8967 - rmse: 22.9121 - val_loss: 671.0396 - val_r2: -1.3111 - val_rmse: 22.1411\n",
      "Epoch 45/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 4007.4196 - r2: 0.8989 - rmse: 23.1951 - val_loss: 491.5123 - val_r2: -0.6928 - val_rmse: 18.5617\n",
      "Epoch 46/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 4265.2602 - r2: 0.9001 - rmse: 23.5950 - val_loss: 1114.2506 - val_r2: -2.8376 - val_rmse: 29.5885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "2972/2972 [==============================] - 0s 38us/step - loss: 4226.7674 - r2: 0.8361 - rmse: 22.9846 - val_loss: 499.0220 - val_r2: -0.7187 - val_rmse: 18.6069\n",
      "Epoch 48/100\n",
      "2972/2972 [==============================] - 0s 40us/step - loss: 4028.4699 - r2: 0.8668 - rmse: 22.4676 - val_loss: 1127.8502 - val_r2: -2.8844 - val_rmse: 29.7401\n",
      "Epoch 49/100\n",
      "2972/2972 [==============================] - 0s 37us/step - loss: 4374.0299 - r2: 0.8874 - rmse: 22.6333 - val_loss: 1390.2239 - val_r2: -3.7880 - val_rmse: 33.8980\n",
      "Epoch 50/100\n",
      "2972/2972 [==============================] - 0s 49us/step - loss: 3860.0457 - r2: 0.9100 - rmse: 22.0228 - val_loss: 1824.3746 - val_r2: -5.2833 - val_rmse: 39.7025\n",
      "Epoch 51/100\n",
      "2972/2972 [==============================] - 0s 50us/step - loss: 3951.5915 - r2: 0.9074 - rmse: 22.4379 - val_loss: 663.7547 - val_r2: -1.2860 - val_rmse: 22.0362\n",
      "Epoch 52/100\n",
      "2972/2972 [==============================] - 0s 47us/step - loss: 3835.3622 - r2: 0.8992 - rmse: 22.4057 - val_loss: 734.2232 - val_r2: -1.5287 - val_rmse: 23.2688\n",
      "Epoch 53/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 4434.9001 - r2: 0.8893 - rmse: 23.3557 - val_loss: 1474.6338 - val_r2: -4.0787 - val_rmse: 35.0395\n",
      "Epoch 54/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 3983.4296 - r2: 0.8999 - rmse: 23.4038 - val_loss: 804.3069 - val_r2: -1.7701 - val_rmse: 24.3617\n",
      "Epoch 55/100\n",
      "2972/2972 [==============================] - 0s 40us/step - loss: 3960.6845 - r2: 0.8303 - rmse: 22.8574 - val_loss: 1266.2070 - val_r2: -3.3609 - val_rmse: 31.9344\n",
      "Epoch 56/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 4236.9467 - r2: 0.8856 - rmse: 23.2014 - val_loss: 899.6133 - val_r2: -2.0983 - val_rmse: 25.8223\n",
      "Epoch 57/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 3676.0332 - r2: 0.8963 - rmse: 21.7419 - val_loss: 993.4532 - val_r2: -2.4215 - val_rmse: 27.4249\n",
      "Epoch 58/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 4312.2311 - r2: 0.8829 - rmse: 22.7373 - val_loss: 810.4282 - val_r2: -1.7912 - val_rmse: 24.4710\n",
      "Epoch 59/100\n",
      "2972/2972 [==============================] - 0s 40us/step - loss: 3221.3121 - r2: 0.9060 - rmse: 21.4923 - val_loss: 572.7057 - val_r2: -0.9724 - val_rmse: 20.2593\n",
      "Epoch 60/100\n",
      "2972/2972 [==============================] - 0s 40us/step - loss: 3450.0658 - r2: 0.9026 - rmse: 21.4786 - val_loss: 875.8799 - val_r2: -2.0166 - val_rmse: 25.4911\n",
      "Epoch 61/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 3407.0309 - r2: 0.9173 - rmse: 21.3352 - val_loss: 968.5577 - val_r2: -2.3358 - val_rmse: 26.8545\n",
      "Epoch 62/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 3652.4944 - r2: 0.9082 - rmse: 21.6932 - val_loss: 1177.3790 - val_r2: -3.0550 - val_rmse: 30.4858\n",
      "Epoch 63/100\n",
      "2972/2972 [==============================] - 0s 38us/step - loss: 3231.3312 - r2: 0.8951 - rmse: 20.8450 - val_loss: 523.1300 - val_r2: -0.8017 - val_rmse: 19.1995\n",
      "Epoch 64/100\n",
      "2972/2972 [==============================] - 0s 37us/step - loss: 3681.0732 - r2: 0.9095 - rmse: 21.9631 - val_loss: 625.0531 - val_r2: -1.1527 - val_rmse: 21.2812\n",
      "Epoch 65/100\n",
      "2972/2972 [==============================] - 0s 44us/step - loss: 3549.4131 - r2: 0.9039 - rmse: 22.2845 - val_loss: 718.3388 - val_r2: -1.4740 - val_rmse: 22.9486\n",
      "Epoch 66/100\n",
      "2972/2972 [==============================] - 0s 45us/step - loss: 3999.1613 - r2: 0.9058 - rmse: 22.0855 - val_loss: 793.7161 - val_r2: -1.7336 - val_rmse: 24.1927\n",
      "Epoch 67/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 3095.8288 - r2: 0.9225 - rmse: 21.1085 - val_loss: 890.8453 - val_r2: -2.0681 - val_rmse: 25.6860\n",
      "Epoch 68/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 4033.1145 - r2: 0.9039 - rmse: 22.5437 - val_loss: 1535.2346 - val_r2: -4.2874 - val_rmse: 35.8350\n",
      "Epoch 69/100\n",
      "2972/2972 [==============================] - 0s 45us/step - loss: 3637.3853 - r2: 0.8957 - rmse: 21.7931 - val_loss: 1237.7295 - val_r2: -3.2628 - val_rmse: 31.4863\n",
      "Epoch 70/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 4136.4425 - r2: 0.8937 - rmse: 22.3010 - val_loss: 775.4542 - val_r2: -1.6707 - val_rmse: 23.8786\n",
      "Epoch 71/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 3627.7724 - r2: 0.9123 - rmse: 21.9233 - val_loss: 982.1239 - val_r2: -2.3825 - val_rmse: 27.0349\n",
      "Epoch 72/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 3678.4918 - r2: 0.8895 - rmse: 21.2419 - val_loss: 1074.7192 - val_r2: -2.7014 - val_rmse: 28.6596\n",
      "Epoch 73/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 3133.2943 - r2: 0.9116 - rmse: 20.9975 - val_loss: 1254.5675 - val_r2: -3.3208 - val_rmse: 31.6596\n",
      "Epoch 74/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 3455.3341 - r2: 0.7300 - rmse: 21.4847 - val_loss: 1786.3354 - val_r2: -5.1523 - val_rmse: 39.2395\n",
      "Epoch 75/100\n",
      "2972/2972 [==============================] - 0s 40us/step - loss: 3678.3493 - r2: 0.8951 - rmse: 21.3970 - val_loss: 856.9784 - val_r2: -1.9515 - val_rmse: 25.1779\n",
      "Epoch 76/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 3877.1142 - r2: 0.9025 - rmse: 21.8705 - val_loss: 797.6947 - val_r2: -1.7473 - val_rmse: 24.2554\n",
      "Epoch 77/100\n",
      "2972/2972 [==============================] - 0s 40us/step - loss: 3810.3994 - r2: 0.9102 - rmse: 21.7113 - val_loss: 761.3618 - val_r2: -1.6222 - val_rmse: 23.6844\n",
      "Epoch 78/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 3180.0682 - r2: 0.7569 - rmse: 20.4043 - val_loss: 1282.2732 - val_r2: -3.4162 - val_rmse: 32.0702\n",
      "Epoch 79/100\n",
      "2972/2972 [==============================] - 0s 44us/step - loss: 3359.3363 - r2: 0.9126 - rmse: 20.9073 - val_loss: 1169.5977 - val_r2: -3.0282 - val_rmse: 30.2603\n",
      "Epoch 80/100\n",
      "2972/2972 [==============================] - 0s 45us/step - loss: 3346.4446 - r2: 0.9142 - rmse: 21.2136 - val_loss: 723.5382 - val_r2: -1.4919 - val_rmse: 23.0403\n",
      "Epoch 81/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 3451.2230 - r2: 0.8246 - rmse: 20.9812 - val_loss: 957.8633 - val_r2: -2.2989 - val_rmse: 26.6403\n",
      "Epoch 82/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 3146.8042 - r2: 0.8520 - rmse: 20.3311 - val_loss: 329.2098 - val_r2: -0.1338 - val_rmse: 14.9841\n",
      "Epoch 83/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 3714.6372 - r2: 0.9094 - rmse: 21.4350 - val_loss: 485.1956 - val_r2: -0.6710 - val_rmse: 18.2708\n",
      "Epoch 84/100\n",
      "2972/2972 [==============================] - 0s 44us/step - loss: 3737.7229 - r2: 0.9100 - rmse: 21.3001 - val_loss: 877.4650 - val_r2: -2.0220 - val_rmse: 25.4984\n",
      "Epoch 85/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 3588.6480 - r2: 0.9131 - rmse: 21.2907 - val_loss: 450.4557 - val_r2: -0.5514 - val_rmse: 17.6519\n",
      "Epoch 86/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 3535.6615 - r2: 0.9166 - rmse: 21.6389 - val_loss: 735.1315 - val_r2: -1.5318 - val_rmse: 23.2489\n",
      "Epoch 87/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 3276.2181 - r2: 0.8739 - rmse: 20.7851 - val_loss: 1315.9507 - val_r2: -3.5322 - val_rmse: 32.5194\n",
      "Epoch 88/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 3174.2484 - r2: 0.9182 - rmse: 20.6890 - val_loss: 482.5334 - val_r2: -0.6619 - val_rmse: 18.2117\n",
      "Epoch 89/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 3787.6583 - r2: 0.9018 - rmse: 21.7936 - val_loss: 1069.0692 - val_r2: -2.6819 - val_rmse: 28.4561\n",
      "Epoch 90/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 3473.3841 - r2: 0.9119 - rmse: 21.6006 - val_loss: 875.0292 - val_r2: -2.0137 - val_rmse: 25.5138\n",
      "Epoch 91/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 2960.1171 - r2: 0.9239 - rmse: 20.0300 - val_loss: 1525.0669 - val_r2: -4.2524 - val_rmse: 35.6699\n",
      "Epoch 92/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 3571.5284 - r2: 0.9053 - rmse: 21.2673 - val_loss: 807.0601 - val_r2: -1.7796 - val_rmse: 24.4450\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2972/2972 [==============================] - 0s 42us/step - loss: 3782.1957 - r2: 0.8508 - rmse: 21.9935 - val_loss: 475.4366 - val_r2: -0.6374 - val_rmse: 18.0908\n",
      "Epoch 94/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 3085.6446 - r2: 0.9237 - rmse: 20.5324 - val_loss: 821.4479 - val_r2: -1.8291 - val_rmse: 24.7222\n",
      "Epoch 95/100\n",
      "2972/2972 [==============================] - 0s 42us/step - loss: 3641.2114 - r2: 0.9103 - rmse: 21.2730 - val_loss: 1129.0518 - val_r2: -2.8885 - val_rmse: 29.5825\n",
      "Epoch 96/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 3772.9576 - r2: 0.9053 - rmse: 21.6307 - val_loss: 599.3248 - val_r2: -1.0641 - val_rmse: 20.7334\n",
      "Epoch 97/100\n",
      "2972/2972 [==============================] - 0s 39us/step - loss: 3305.3844 - r2: 0.9157 - rmse: 20.4367 - val_loss: 806.5485 - val_r2: -1.7778 - val_rmse: 24.4694\n",
      "Epoch 98/100\n",
      "2972/2972 [==============================] - 0s 41us/step - loss: 3454.8421 - r2: 0.8378 - rmse: 20.6174 - val_loss: 851.1755 - val_r2: -1.9315 - val_rmse: 25.1403\n",
      "Epoch 99/100\n",
      "2972/2972 [==============================] - 0s 44us/step - loss: 3302.5198 - r2: 0.8246 - rmse: 20.7726 - val_loss: 1013.0381 - val_r2: -2.4890 - val_rmse: 27.5463\n",
      "Epoch 100/100\n",
      "2972/2972 [==============================] - 0s 43us/step - loss: 3571.9200 - r2: 0.9122 - rmse: 21.1396 - val_loss: 1270.1147 - val_r2: -3.3744 - val_rmse: 31.8746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a26690400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=X.shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=[r2, rmse])\n",
    "\n",
    "model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=100,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers import LSTM\n",
    "\n",
    "def ts_to_supervised(data, lag=1):\n",
    "    df = pd.DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = pd.concat(columns, axis=1)\n",
    "    df.fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return(pd.Series(diff))\n",
    "\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]\n",
    "\n",
    "def scale(train, test):\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    train_scaled = scaler.fit_transform(train)\n",
    "    test_scaled = scaler.fit_transform(test)\n",
    "    return scaler, train_scaled, test_scaled\n",
    "\n",
    "def invert_scale(scaler, X, value):\n",
    "    new_row = [x for x in X] + [value]\n",
    "    array = np.array(new_row)\n",
    "    array = array.reshape(1, len(array))\n",
    "    inverted = scaler.inverse_transform(array)\n",
    "    return inverted[0, -1]\n",
    "\n",
    "def fit_lstm(train, nb_epoch, batch_size=1, neurons=4):\n",
    "    X, y = train[:, 0:-1], train[:, -1]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        neurons,\n",
    "        batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model\n",
    "\n",
    "def forecast_lstm(model, batch_size, X):\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    yhat = model.predict(X, batch_size=batch_size)\n",
    "    return yhat[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eth_close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-06</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-07</th>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-08</th>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            eth_close\n",
       "date                 \n",
       "2015-08-06        3.0\n",
       "2015-08-07        1.2\n",
       "2015-08-08        1.2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set time series\n",
    "ts = df_orig[['date','eth_close']].copy()\n",
    "ts = ts[ts.eth_close.isnull().sum():]\n",
    "ts.set_index('date', inplace=True, drop=True)\n",
    "ts.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = ts.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# difference for stationarity\n",
    "ts_diff = difference(ts, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform for supervised learning\n",
    "ts_sup = ts_to_supervised(ts_diff, 1)\n",
    "ts_sup = ts_sup.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set train/test\n",
    "train = ts_sup[:-8]\n",
    "test = ts_sup[-8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# scale\n",
    "scaler, train_scaled, test_scaled = scale(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit_lstm\n",
    "model = fit_lstm(train_scaled, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19716528],\n",
       "       [0.19637135],\n",
       "       [0.19581531],\n",
       "       ...,\n",
       "       [0.19407764],\n",
       "       [0.19154026],\n",
       "       [0.19264302]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reshaped = train_scaled[:, 0].reshape(len(train_scaled), 1, 1)\n",
    "model.predict(train_reshaped, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: [236.54194131], expected: [229.52]\n",
      "predicted: [236.23588022], expected: [215.14]\n",
      "predicted: [221.43675514], expected: [196.77]\n",
      "predicted: [203.35461501], expected: [195.99]\n",
      "predicted: [202.63181951], expected: [197.14]\n",
      "predicted: [203.46593378], expected: [185.15]\n",
      "predicted: [192.1722706], expected: [183.03]\n",
      "predicted: [189.30186737], expected: [206.03]\n"
     ]
    }
   ],
   "source": [
    "predictions = list()\n",
    "for i in range(len(test_scaled)):\n",
    "    X, y = test_scaled[i, 0:-1], test_scaled[i, -1]\n",
    "    yhat = forecast_lstm(model, 1, X)\n",
    "    yhat = invert_scale(scaler, X, yhat)\n",
    "    yhat = inverse_difference(ts, yhat, len(test_scaled) + 1 - i)\n",
    "    predictions.append(yhat)\n",
    "    expected = ts[len(train) + i + 1]\n",
    "    print('predicted: {}, expected: {}'.format(yhat, expected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test r2: [0.21402416]\n",
      "test rmse: 15.354458756853072\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def r2_lstm(observed, predicted):\n",
    "    ss_resid = sum((observed - predicted) ** 2)\n",
    "    ss_tot = sum((observed - np.mean(predicted)) ** 2)\n",
    "    r2 = 1 - (ss_resid / ss_tot)\n",
    "    return r2\n",
    "\n",
    "def rmse_lstm(observed, predicted):\n",
    "    rmse = np.sqrt(mean_squared_error(observed, predicted))\n",
    "    return rmse\n",
    "\n",
    "print('test r2: {}'.format(r2_lstm(ts[-8:], predictions)))\n",
    "print('test rmse: {}'.format(rmse_lstm(ts[-8:], predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(11,6))\n",
    "plt.plot(df[-8:].index,\n",
    "         predictions,\n",
    "         label='forecast, ts only\\nrmse = {:.4f}'.format(\n",
    "             rmse_lstm(ts[-8:], predictions)),\n",
    "         c=colors[1]\n",
    "        )\n",
    "plt.scatter(df[-8:].index,\n",
    "            ts[-8:],\n",
    "            label='observed')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM RNN with Exogenous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[1:, 8:]\n",
    "#X.drop(['eth_volumefrom', 'eth_volumeto'], axis=1, inplace=True)\n",
    "#X = df.loc[:, ~df.columns.isin(['eth_close', 'date'])][1:]\n",
    "y = df.shift(1).eth_close[1:]\n",
    "\n",
    "X_train = np.array(X.iloc[:-8,:])\n",
    "X_test = np.array(X.iloc[-8:,:])\n",
    "y_train = np.array(y.iloc[:-8])\n",
    "y_test = np.array(y.iloc[-8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
